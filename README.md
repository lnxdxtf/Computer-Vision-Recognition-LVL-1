<h1>Computer Vision Recognition LVL 1</h1>
<h2>

> Status: Developing âš ï¸
<img src = "Images/develop.gif">

</h2>

<h2>Project Steps</h2>

<h3>

 1. ğŸ“  Develop .py modules :
</h3>

<h4>

> * ğŸ“ âœ”ï¸ Detecion and Tracking Hands<br/>
>
> * ğŸ“ ğŸš§ (DEV) Detection,Tracking and Face Mesh<br/>
>
> * ğŸ“ âœ”ï¸ (DEV) Pose<br/>
>
> * âš ï¸ Possible Creation of New Modules(DEVELOPING)<br/>
</h4>

<h3>
2. ğŸ“ Develop code that read gestures âš ï¸(NEXT STEP)
</h3>



<h2>
Technologies Used:
</h2>

<h4>

>
>Python 3.7*<br/>
>
>TensorFlow<br/>
>
>OpenCV<br/>
>
>MediaPipe(google)<br/>
>
>Maybe a new technologyâš ï¸</br>
>

</h4>


<h2>Preview Code Running</h2>

<h3>

* Detect Hand

<img src = "Images/detecÃ§ao_maogif.gif">

* Pose

<img src = "Images/pose_01.gif">

</h3>


<h1>âš ï¸CODE COMMENTED ON PORTUGUESEâš ï¸

>

ğŸ’» How to Run: </h1>



<h2>Detect Hand âœ‹ </h2>

<h3>

>* Open the folder hands_github 
>* Run DetectHand_01 .py
>* Set your Video Capture; Set 0 if you only have a webcam; Try 1+ if you have more than one
>* Just Run Now
>
><img src='hands_github/hand_pts.png'>

</h3>


<h2>Pose ğŸ¦¾ </h2>

<h3>

>* Open the folder pose_estimation
>
>* Set your Video Capture; v0 = 0 or v1 = dir to videos 
>* You could also change the videos in the dir. In the variable 'v1'change the ending between 1.mp4 | 2.mp4 | 3.mp4 |4.mp4 | 5.mp4  in the folder.
>
>* Just Run Now (Pose_Run.py)
>
><img src='pose_estimation/landmarks_pose.png'>

</h3>

<h2>Face Detection and Face Mesh (Developing)ğŸš§ </h2>

